{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq to Seq - Machine translation (spanish to english)",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLpSGgPoxJ2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, sys\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, GRU, Dense, Embedding\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaS61JyS0FJF",
        "colab_type": "code",
        "outputId": "5647945a-54d0-459b-ec60-cee90648dc7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y003cAXXzIPO",
        "colab_type": "code",
        "outputId": "0b11f2d9-bef9-403c-ac16-86ddfaa6e478",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# some config\n",
        "BATCH_SIZE = 64  # Batch size for training.\n",
        "EPOCHS = 100  # Number of epochs to train for.\n",
        "LATENT_DIM = 256  # Latent dimensionality of the encoding space.\n",
        "NUM_SAMPLES = 20000  # Number of samples to train on.\n",
        "MAX_SEQUENCE_LENGTH = 100\n",
        "MAX_NUM_WORDS = 20000\n",
        "EMBEDDING_DIM = 100\n",
        "\n",
        "# Where we will store the data\n",
        "input_texts = [] # sentence in original language\n",
        "target_texts = [] # sentence in target language\n",
        "target_texts_inputs = [] # sentence in target language offset by 1\n",
        "\n",
        "\n",
        "# load in the data\n",
        "# download the data at: http://www.manythings.org/anki/\n",
        "t = 0\n",
        "for line in open('/content/gdrive/My Drive/NLP project/spa.txt'):\n",
        "  # only keep a limited number of samples\n",
        "  t += 1\n",
        "  if t > NUM_SAMPLES:\n",
        "    break\n",
        "\n",
        "  # input and target are separated by tab\n",
        "  if '\\t' not in line:\n",
        "    continue\n",
        "\n",
        "  # split up the input and translation\n",
        "  input_text, translation = line.rstrip().split('\\t')\n",
        "\n",
        "  # make the target input and output\n",
        "  # recall we'll be using teacher forcing\n",
        "  target_text = translation + ' <eos>'\n",
        "  target_text_input = '<sos> ' + translation\n",
        "\n",
        "  input_texts.append(input_text)\n",
        "  target_texts.append(target_text)\n",
        "  target_texts_inputs.append(target_text_input)\n",
        "print(\"num samples:\", len(input_texts))\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num samples: 20000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIVvteSSonpe",
        "colab_type": "code",
        "outputId": "04be5c18-6bb8-45ec-8a58-2e27ec954f79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# tokenize the inputs\n",
        "tokenizer_inputs = Tokenizer(num_words=MAX_NUM_WORDS)\n",
        "tokenizer_inputs.fit_on_texts(input_texts)\n",
        "input_sequences = tokenizer_inputs.texts_to_sequences(input_texts)\n",
        "\n",
        "# get the word to index mapping for input language\n",
        "word2idx_inputs = tokenizer_inputs.word_index\n",
        "print('Found %s unique input tokens.' % len(word2idx_inputs))\n",
        "\n",
        "# determine maximum length input sequence\n",
        "max_len_input = max(len(s) for s in input_sequences)\n",
        "\n",
        "# tokenize the outputs\n",
        "# don't filter out special characters\n",
        "# otherwise <sos> and <eos> won't appear\n",
        "tokenizer_outputs = Tokenizer(num_words=MAX_NUM_WORDS, filters='')\n",
        "tokenizer_outputs.fit_on_texts(target_texts + target_texts_inputs) # inefficient, oh well\n",
        "target_sequences = tokenizer_outputs.texts_to_sequences(target_texts)\n",
        "target_sequences_inputs = tokenizer_outputs.texts_to_sequences(target_texts_inputs)\n",
        "\n",
        "# get the word to index mapping for output language\n",
        "word2idx_outputs = tokenizer_outputs.word_index\n",
        "print('Found %s unique output tokens.' % len(word2idx_outputs))\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3827 unique input tokens.\n",
            "Found 10570 unique output tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SY_e4CIqs-u6",
        "colab_type": "code",
        "outputId": "30e8b1bd-d378-4d00-9642-3cb2e58bfd66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# store number of output words for later\n",
        "# remember to add 1 since indexing starts at 1\n",
        "num_words_output = len(word2idx_outputs) + 1\n",
        "\n",
        "# determine maximum length output sequence\n",
        "max_len_target = max(len(s) for s in target_sequences)\n",
        "max_len_target"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_gcrFbFtZJP",
        "colab_type": "code",
        "outputId": "0f3017b5-b75c-44e5-b1e4-6725d91918ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# pad the sequences\n",
        "encoder_inputs = pad_sequences(input_sequences, maxlen=max_len_input)\n",
        "print(\"encoder_inputs.shape:\", encoder_inputs.shape)\n",
        "print(\"encoder_inputs[0]:\", encoder_inputs[0])\n",
        "\n",
        "decoder_inputs = pad_sequences(target_sequences_inputs, maxlen=max_len_target, padding='post')\n",
        "print(\"decoder_inputs[0]:\", decoder_inputs[0])\n",
        "print(\"decoder_inputs.shape:\", decoder_inputs.shape)\n",
        "\n",
        "decoder_targets = pad_sequences(target_sequences, maxlen=max_len_target, padding='post')\n",
        "\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "encoder_inputs.shape: (20000, 6)\n",
            "encoder_inputs[0]: [ 0  0  0  0  0 23]\n",
            "decoder_inputs[0]: [   2 2889    0    0    0    0    0    0    0    0    0    0    0]\n",
            "decoder_inputs.shape: (20000, 13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-0y8xpOuLCQ",
        "colab_type": "code",
        "outputId": "56db394f-80e7-4aff-a70a-f30febeea683",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# store all the pre-trained word vectors\n",
        "print('Loading word vectors...')\n",
        "word2vec = {}\n",
        "with open(os.path.join('/content/gdrive/My Drive/NLP project/glove.6B/glove.6B.%sd.txt' % EMBEDDING_DIM)) as f:\n",
        "  # is just a space-separated text file in the format:\n",
        "  # word vec[0] vec[1] vec[2] ...\n",
        "  for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    vec = np.asarray(values[1:], dtype='float32')\n",
        "    word2vec[word] = vec\n",
        "\n",
        "print('Found %s word vectors.' % len(word2vec))\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading word vectors...\n",
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHSTv3wGucZJ",
        "colab_type": "code",
        "outputId": "2cff02b1-53ca-4e6a-f702-47452e6885c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "word2vec[\"yellow\"].shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfjQWim8A3IZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9d973719-a259-4b31-d687-c334d372ea3e"
      },
      "source": [
        "# prepare embedding matrix\n",
        "print('Filling pre-trained embeddings...')\n",
        "num_words = min(MAX_NUM_WORDS, len(word2idx_inputs) + 1)\n",
        "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
        "#print(embedding_matrix.shape)\n",
        "for word, i in word2idx_inputs.items():\n",
        "  if i < MAX_NUM_WORDS:\n",
        "    #print(word,i)\n",
        "    embedding_vector = word2vec.get(word)\n",
        "    if embedding_vector is not None:\n",
        "      # words not found in embedding index will be all zeros.\n",
        "      embedding_matrix[i] = embedding_vector\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Filling pre-trained embeddings...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNengCghXQUy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "57471cda-c87b-4a9f-94ed-47f2e8400d5b"
      },
      "source": [
        "# create embedding layer\n",
        "embedding_layer = Embedding(\n",
        "  num_words,\n",
        "  EMBEDDING_DIM,\n",
        "  weights=[embedding_matrix],\n",
        "  input_length=max_len_input,\n",
        "  # trainable=True\n",
        ")\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.embeddings.Embedding at 0x7fbf9e21ab70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVwO52wnahfe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create embedding layer\n",
        "# create targets, since we cannot use sparse\n",
        "# categorical cross entropy when we have sequences\n",
        "\n",
        "decoder_targets_one_hot = np.zeros(\n",
        "  (\n",
        "    len(input_texts),\n",
        "    max_len_target,\n",
        "    num_words_output\n",
        "  ),\n",
        "  dtype='float32'\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaBR_30SajAo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8f59f242-77eb-42a9-996f-744c55a049b9"
      },
      "source": [
        "decoder_targets_one_hot.shape"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 13, 10571)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyFjl28F6hYU",
        "colab_type": "code",
        "outputId": "5488cde5-1e63-4f2e-ae8f-fe84faa16dd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4638
        }
      },
      "source": [
        "\n",
        "# create embedding layer\n",
        "\n",
        "# create targets, since we cannot use sparse\n",
        "# categorical cross entropy when we have sequences\n",
        "decoder_targets_one_hot = np.zeros(\n",
        "  (\n",
        "    len(input_texts),\n",
        "    max_len_target,\n",
        "    num_words_output\n",
        "  ),\n",
        "  dtype='float32'\n",
        ")\n",
        "\n",
        "# assign the values\n",
        "for i, d in enumerate(decoder_targets):\n",
        "  for t, word in enumerate(d):\n",
        "    decoder_targets_one_hot[i, t, word] = 1\n",
        "\n",
        "\n",
        "##### build the model #####\n",
        "encoder_inputs_placeholder = Input(shape=(max_len_input,))\n",
        "x = embedding_layer(encoder_inputs_placeholder)\n",
        "encoder = LSTM(\n",
        "  LATENT_DIM,\n",
        "  return_state=True,\n",
        "  # dropout=0.5 # dropout not available on gpu\n",
        ")\n",
        "encoder_outputs, h, c = encoder(x)\n",
        "# encoder_outputs, h = encoder(x) #gru\n",
        "\n",
        "# keep only the states to pass into decoder\n",
        "encoder_states = [h, c]\n",
        "# encoder_states = [state_h] # gru\n",
        "\n",
        "# Set up the decoder, using [h, c] as initial state.\n",
        "decoder_inputs_placeholder = Input(shape=(max_len_target,))\n",
        "\n",
        "# this word embedding will not use pre-trained vectors\n",
        "# although you could\n",
        "decoder_embedding = Embedding(num_words_output, LATENT_DIM)\n",
        "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)\n",
        "\n",
        "# since the decoder is a \"to-many\" model we want to have\n",
        "# return_sequences=True\n",
        "decoder_lstm = LSTM(\n",
        "  LATENT_DIM,\n",
        "  return_sequences=True,\n",
        "  return_state=True,\n",
        "  # dropout=0.5 # dropout not available on gpu\n",
        ")\n",
        "decoder_outputs, _, _ = decoder_lstm(\n",
        "  decoder_inputs_x,\n",
        "  initial_state=encoder_states\n",
        ")\n",
        "\n",
        "# decoder_outputs, _ = decoder_gru(\n",
        "#   decoder_inputs_x,\n",
        "#   initial_state=encoder_states\n",
        "# )\n",
        "\n",
        "# final dense layer for predictions\n",
        "decoder_dense = Dense(num_words_output, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Create the model object\n",
        "model = Model([encoder_inputs_placeholder, decoder_inputs_placeholder], decoder_outputs)\n",
        "\n",
        "# Compile the model and train it\n",
        "model.compile(\n",
        "  optimizer='rmsprop',\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "r = model.fit(\n",
        "  [encoder_inputs, decoder_inputs], decoder_targets_one_hot,\n",
        "  batch_size=BATCH_SIZE,\n",
        "  epochs=EPOCHS,\n",
        "  validation_split=0.2,\n",
        ")\n",
        "\n",
        "# plot some data\n",
        "plt.plot(r.history['loss'], label='loss')\n",
        "plt.plot(r.history['val_loss'], label='val_loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# accuracies\n",
        "plt.plot(r.history['acc'], label='acc')\n",
        "plt.plot(r.history['val_acc'], label='val_acc')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Save model\n",
        "model.save('s2s.h5')\n",
        "n\n",
        "\n",
        "##### Make predictions #####\n",
        "# As with the poetry example, we need to create another model\n",
        "# that can take in the RNN state and previous word as input\n",
        "# and accept a T=1 sequence.\n",
        "\n",
        "# The encoder will be stand-alone\n",
        "# From this we will get our initial decoder hidden state\n",
        "encoder_model = Model(encoder_inputs_placeholder, encoder_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(LATENT_DIM,))\n",
        "decoder_state_input_c = Input(shape=(LATENT_DIM,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "# decoder_states_inputs = [decoder_state_input_h] # gru\n",
        "\n",
        "decoder_inputs_single = Input(shape=(1,))\n",
        "decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)\n",
        "\n",
        "\n",
        "# this time, we want to keep the states too, to be output\n",
        "# by our sampling model\n",
        "decoder_outputs, h, c = decoder_lstm(\n",
        "  decoder_inputs_single_x,\n",
        "  initial_state=decoder_states_inputs\n",
        ")\n",
        "# decoder_outputs, state_h = decoder_lstm(\n",
        "#   decoder_inputs_single_x,\n",
        "#   initial_state=decoder_states_inputs\n",
        "# ) #gru\n",
        "decoder_states = [h, c]\n",
        "# decoder_states = [h] # gru\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# The sampling model\n",
        "# inputs: y(t-1), h(t-1), c(t-1)\n",
        "# outputs: y(t), h(t), c(t)\n",
        "decoder_model = Model(\n",
        "  [decoder_inputs_single] + decoder_states_inputs, \n",
        "  [decoder_outputs] + decoder_states\n",
        ")\n",
        "\n",
        "# map indexes back into real words\n",
        "# so we can view the results\n",
        "idx2word_eng = {v:k for k, v in word2idx_inputs.items()}\n",
        "idx2word_trans = {v:k for k, v in word2idx_outputs.items()}\n",
        "\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "  # Encode the input as state vectors.\n",
        "  states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "  # Generate empty target sequence of length 1.\n",
        "  target_seq = np.zeros((1, 1))\n",
        "\n",
        "  # Populate the first character of target sequence with the start character.\n",
        "  # NOTE: tokenizer lower-cases all words\n",
        "  target_seq[0, 0] = word2idx_outputs['<sos>']\n",
        "\n",
        "  # if we get this we break\n",
        "  eos = word2idx_outputs['<eos>']\n",
        "\n",
        "  # Create the translation\n",
        "  output_sentence = []\n",
        "  for _ in range(max_len_target):\n",
        "    output_tokens, h, c = decoder_model.predict(\n",
        "      [target_seq] + states_value\n",
        "    )\n",
        "    # output_tokens, h = decoder_model.predict(\n",
        "    #     [target_seq] + states_value\n",
        "    # ) # gru\n",
        "\n",
        "    # Get next word\n",
        "    idx = np.argmax(output_tokens[0, 0, :])\n",
        "\n",
        "    # End sentence of EOS\n",
        "    if eos == idx:\n",
        "      break\n",
        "\n",
        "    word = ''\n",
        "    if idx > 0:\n",
        "      word = idx2word_trans[idx]\n",
        "      output_sentence.append(word)\n",
        "\n",
        "    # Update the decoder input\n",
        "    # which is just the word just generated\n",
        "    target_seq[0, 0] = idx\n",
        "\n",
        "    # Update states\n",
        "    states_value = [h, c]\n",
        "    # states_value = [h] # gru\n",
        "\n",
        "  return ' '.join(output_sentence)\n",
        "\n",
        "\n",
        "\n",
        "while True:\n",
        "  # Do some test translations\n",
        "  i = np.random.choice(len(input_texts))\n",
        "  input_seq = encoder_inputs[i:i+1]\n",
        "  translation = decode_sequence(input_seq)\n",
        "  print('-')\n",
        "  print('Input:', input_texts[i])\n",
        "  print('Translation:', translation)\n",
        "\n",
        "  ans = input(\"Continue? [Y/n]\")\n",
        "  if ans and ans.lower().startswith('n'):\n",
        "    break\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2364 unique input tokens.\n",
            "Found 6294 unique output tokens.\n",
            "encoder_inputs.shape: (10000, 5)\n",
            "encoder_inputs[0]: [ 0  0  0  0 14]\n",
            "decoder_inputs[0]: [   2 1480    0    0    0    0    0    0    0]\n",
            "decoder_inputs.shape: (10000, 9)\n",
            "Loading word vectors...\n",
            "Found 400000 word vectors.\n",
            "Filling pre-trained embeddings...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Train on 8000 samples, validate on 2000 samples\n",
            "Epoch 1/100\n",
            "8000/8000 [==============================] - 8s 1ms/step - loss: 2.6427 - acc: 0.6596 - val_loss: 2.6036 - val_acc: 0.6598\n",
            "Epoch 2/100\n",
            "8000/8000 [==============================] - 6s 740us/step - loss: 2.0105 - acc: 0.7156 - val_loss: 2.4163 - val_acc: 0.6745\n",
            "Epoch 3/100\n",
            "8000/8000 [==============================] - 6s 735us/step - loss: 1.7926 - acc: 0.7374 - val_loss: 2.2470 - val_acc: 0.6955\n",
            "Epoch 4/100\n",
            "8000/8000 [==============================] - 6s 780us/step - loss: 1.6338 - acc: 0.7555 - val_loss: 2.1358 - val_acc: 0.7101\n",
            "Epoch 5/100\n",
            "8000/8000 [==============================] - 6s 780us/step - loss: 1.4982 - acc: 0.7711 - val_loss: 2.0561 - val_acc: 0.7212\n",
            "Epoch 6/100\n",
            "8000/8000 [==============================] - 6s 740us/step - loss: 1.3828 - acc: 0.7850 - val_loss: 1.9940 - val_acc: 0.7323\n",
            "Epoch 7/100\n",
            "8000/8000 [==============================] - 6s 737us/step - loss: 1.2833 - acc: 0.7944 - val_loss: 1.9964 - val_acc: 0.7332\n",
            "Epoch 8/100\n",
            "8000/8000 [==============================] - 6s 739us/step - loss: 1.2020 - acc: 0.8039 - val_loss: 1.9834 - val_acc: 0.7353\n",
            "Epoch 9/100\n",
            "8000/8000 [==============================] - 6s 740us/step - loss: 1.1290 - acc: 0.8137 - val_loss: 1.9826 - val_acc: 0.7317\n",
            "Epoch 10/100\n",
            "8000/8000 [==============================] - 6s 737us/step - loss: 1.0621 - acc: 0.8222 - val_loss: 1.9616 - val_acc: 0.7320\n",
            "Epoch 11/100\n",
            "8000/8000 [==============================] - 6s 736us/step - loss: 0.9976 - acc: 0.8304 - val_loss: 1.9928 - val_acc: 0.7277\n",
            "Epoch 12/100\n",
            "8000/8000 [==============================] - 6s 739us/step - loss: 0.9400 - acc: 0.8384 - val_loss: 1.9658 - val_acc: 0.7297\n",
            "Epoch 13/100\n",
            "8000/8000 [==============================] - 6s 737us/step - loss: 0.8883 - acc: 0.8458 - val_loss: 1.9939 - val_acc: 0.7262\n",
            "Epoch 14/100\n",
            "8000/8000 [==============================] - 6s 739us/step - loss: 0.8391 - acc: 0.8533 - val_loss: 2.0050 - val_acc: 0.7281\n",
            "Epoch 15/100\n",
            "8000/8000 [==============================] - 6s 740us/step - loss: 0.7925 - acc: 0.8603 - val_loss: 2.0083 - val_acc: 0.7289\n",
            "Epoch 16/100\n",
            "8000/8000 [==============================] - 6s 741us/step - loss: 0.7506 - acc: 0.8669 - val_loss: 2.0239 - val_acc: 0.7293\n",
            "Epoch 17/100\n",
            "8000/8000 [==============================] - 6s 769us/step - loss: 0.7119 - acc: 0.8727 - val_loss: 2.0248 - val_acc: 0.7307\n",
            "Epoch 18/100\n",
            "8000/8000 [==============================] - 7s 835us/step - loss: 0.6774 - acc: 0.8784 - val_loss: 2.0418 - val_acc: 0.7301\n",
            "Epoch 19/100\n",
            "8000/8000 [==============================] - 6s 768us/step - loss: 0.6431 - acc: 0.8836 - val_loss: 2.0844 - val_acc: 0.7288\n",
            "Epoch 20/100\n",
            "8000/8000 [==============================] - 6s 739us/step - loss: 0.6094 - acc: 0.8883 - val_loss: 2.0980 - val_acc: 0.7303\n",
            "Epoch 21/100\n",
            "8000/8000 [==============================] - 6s 730us/step - loss: 0.5780 - acc: 0.8927 - val_loss: 2.0915 - val_acc: 0.7293\n",
            "Epoch 22/100\n",
            "8000/8000 [==============================] - 6s 734us/step - loss: 0.5489 - acc: 0.8970 - val_loss: 2.1121 - val_acc: 0.7299\n",
            "Epoch 23/100\n",
            "8000/8000 [==============================] - 6s 740us/step - loss: 0.5199 - acc: 0.9025 - val_loss: 2.1367 - val_acc: 0.7303\n",
            "Epoch 24/100\n",
            "8000/8000 [==============================] - 6s 741us/step - loss: 0.4912 - acc: 0.9057 - val_loss: 2.1315 - val_acc: 0.7306\n",
            "Epoch 25/100\n",
            "8000/8000 [==============================] - 6s 741us/step - loss: 0.4654 - acc: 0.9101 - val_loss: 2.1346 - val_acc: 0.7321\n",
            "Epoch 26/100\n",
            "8000/8000 [==============================] - 6s 748us/step - loss: 0.4414 - acc: 0.9134 - val_loss: 2.1470 - val_acc: 0.7318\n",
            "Epoch 27/100\n",
            "8000/8000 [==============================] - 6s 781us/step - loss: 0.4212 - acc: 0.9171 - val_loss: 2.1493 - val_acc: 0.7304\n",
            "Epoch 28/100\n",
            "8000/8000 [==============================] - 6s 763us/step - loss: 0.4042 - acc: 0.9201 - val_loss: 2.1605 - val_acc: 0.7291\n",
            "Epoch 29/100\n",
            "8000/8000 [==============================] - 6s 746us/step - loss: 0.3854 - acc: 0.9240 - val_loss: 2.1665 - val_acc: 0.7305\n",
            "Epoch 30/100\n",
            "8000/8000 [==============================] - 6s 743us/step - loss: 0.3690 - acc: 0.9266 - val_loss: 2.1800 - val_acc: 0.7309\n",
            "Epoch 31/100\n",
            "8000/8000 [==============================] - 6s 797us/step - loss: 0.3532 - acc: 0.9289 - val_loss: 2.1950 - val_acc: 0.7295\n",
            "Epoch 32/100\n",
            "8000/8000 [==============================] - 6s 779us/step - loss: 0.3383 - acc: 0.9321 - val_loss: 2.2058 - val_acc: 0.7302\n",
            "Epoch 33/100\n",
            "8000/8000 [==============================] - 6s 744us/step - loss: 0.3229 - acc: 0.9340 - val_loss: 2.2119 - val_acc: 0.7311\n",
            "Epoch 34/100\n",
            "8000/8000 [==============================] - 6s 743us/step - loss: 0.3108 - acc: 0.9366 - val_loss: 2.2287 - val_acc: 0.7293\n",
            "Epoch 35/100\n",
            "8000/8000 [==============================] - 6s 742us/step - loss: 0.2968 - acc: 0.9389 - val_loss: 2.2451 - val_acc: 0.7289\n",
            "Epoch 36/100\n",
            "8000/8000 [==============================] - 6s 739us/step - loss: 0.2823 - acc: 0.9416 - val_loss: 2.2360 - val_acc: 0.7298\n",
            "Epoch 37/100\n",
            "8000/8000 [==============================] - 6s 742us/step - loss: 0.2700 - acc: 0.9440 - val_loss: 2.2650 - val_acc: 0.7288\n",
            "Epoch 38/100\n",
            "8000/8000 [==============================] - 6s 743us/step - loss: 0.2615 - acc: 0.9454 - val_loss: 2.2676 - val_acc: 0.7277\n",
            "Epoch 39/100\n",
            "8000/8000 [==============================] - 6s 748us/step - loss: 0.2539 - acc: 0.9456 - val_loss: 2.2666 - val_acc: 0.7271\n",
            "Epoch 40/100\n",
            "8000/8000 [==============================] - 6s 743us/step - loss: 0.2457 - acc: 0.9472 - val_loss: 2.2861 - val_acc: 0.7265\n",
            "Epoch 41/100\n",
            "8000/8000 [==============================] - 6s 743us/step - loss: 0.2382 - acc: 0.9481 - val_loss: 2.2866 - val_acc: 0.7262\n",
            "Epoch 42/100\n",
            "8000/8000 [==============================] - 6s 737us/step - loss: 0.2311 - acc: 0.9493 - val_loss: 2.2875 - val_acc: 0.7270\n",
            "Epoch 43/100\n",
            "8000/8000 [==============================] - 6s 735us/step - loss: 0.2232 - acc: 0.9503 - val_loss: 2.2926 - val_acc: 0.7271\n",
            "Epoch 44/100\n",
            "8000/8000 [==============================] - 6s 762us/step - loss: 0.2158 - acc: 0.9514 - val_loss: 2.3024 - val_acc: 0.7254\n",
            "Epoch 45/100\n",
            "8000/8000 [==============================] - 6s 790us/step - loss: 0.2095 - acc: 0.9513 - val_loss: 2.3175 - val_acc: 0.7243\n",
            "Epoch 46/100\n",
            "8000/8000 [==============================] - 6s 736us/step - loss: 0.2024 - acc: 0.9524 - val_loss: 2.3158 - val_acc: 0.7252\n",
            "Epoch 47/100\n",
            "8000/8000 [==============================] - 6s 744us/step - loss: 0.1975 - acc: 0.9528 - val_loss: 2.3423 - val_acc: 0.7252\n",
            "Epoch 48/100\n",
            "8000/8000 [==============================] - 6s 736us/step - loss: 0.1915 - acc: 0.9538 - val_loss: 2.3127 - val_acc: 0.7253\n",
            "Epoch 49/100\n",
            "8000/8000 [==============================] - 6s 734us/step - loss: 0.1863 - acc: 0.9536 - val_loss: 2.3455 - val_acc: 0.7241\n",
            "Epoch 50/100\n",
            "8000/8000 [==============================] - 6s 733us/step - loss: 0.1819 - acc: 0.9541 - val_loss: 2.3406 - val_acc: 0.7273\n",
            "Epoch 51/100\n",
            "8000/8000 [==============================] - 6s 733us/step - loss: 0.1763 - acc: 0.9551 - val_loss: 2.3566 - val_acc: 0.7234\n",
            "Epoch 52/100\n",
            "8000/8000 [==============================] - 6s 736us/step - loss: 0.1721 - acc: 0.9549 - val_loss: 2.3572 - val_acc: 0.7253\n",
            "Epoch 53/100\n",
            "8000/8000 [==============================] - 6s 738us/step - loss: 0.1677 - acc: 0.9551 - val_loss: 2.3706 - val_acc: 0.7243\n",
            "Epoch 54/100\n",
            "8000/8000 [==============================] - 6s 735us/step - loss: 0.1641 - acc: 0.9556 - val_loss: 2.3717 - val_acc: 0.7231\n",
            "Epoch 55/100\n",
            "8000/8000 [==============================] - 6s 738us/step - loss: 0.1602 - acc: 0.9553 - val_loss: 2.3916 - val_acc: 0.7246\n",
            "Epoch 56/100\n",
            "8000/8000 [==============================] - 6s 738us/step - loss: 0.1569 - acc: 0.9555 - val_loss: 2.3877 - val_acc: 0.7254\n",
            "Epoch 57/100\n",
            "8000/8000 [==============================] - 6s 743us/step - loss: 0.1535 - acc: 0.9556 - val_loss: 2.4087 - val_acc: 0.7236\n",
            "Epoch 58/100\n",
            "8000/8000 [==============================] - 6s 790us/step - loss: 0.1502 - acc: 0.9557 - val_loss: 2.4020 - val_acc: 0.7236\n",
            "Epoch 59/100\n",
            "8000/8000 [==============================] - 6s 762us/step - loss: 0.1474 - acc: 0.9556 - val_loss: 2.3897 - val_acc: 0.7226\n",
            "Epoch 60/100\n",
            "8000/8000 [==============================] - 6s 740us/step - loss: 0.1454 - acc: 0.9559 - val_loss: 2.4105 - val_acc: 0.7229\n",
            "Epoch 61/100\n",
            "8000/8000 [==============================] - 6s 740us/step - loss: 0.1419 - acc: 0.9562 - val_loss: 2.4201 - val_acc: 0.7247\n",
            "Epoch 62/100\n",
            "8000/8000 [==============================] - 6s 742us/step - loss: 0.1398 - acc: 0.9561 - val_loss: 2.4222 - val_acc: 0.7244\n",
            "Epoch 63/100\n",
            "8000/8000 [==============================] - 6s 745us/step - loss: 0.1370 - acc: 0.9563 - val_loss: 2.4203 - val_acc: 0.7228\n",
            "Epoch 64/100\n",
            "8000/8000 [==============================] - 6s 740us/step - loss: 0.1342 - acc: 0.9562 - val_loss: 2.4377 - val_acc: 0.7225\n",
            "Epoch 65/100\n",
            "8000/8000 [==============================] - 6s 741us/step - loss: 0.1317 - acc: 0.9563 - val_loss: 2.4509 - val_acc: 0.7244\n",
            "Epoch 66/100\n",
            "8000/8000 [==============================] - 6s 743us/step - loss: 0.1300 - acc: 0.9563 - val_loss: 2.4501 - val_acc: 0.7221\n",
            "Epoch 67/100\n",
            "8000/8000 [==============================] - 6s 736us/step - loss: 0.1280 - acc: 0.9563 - val_loss: 2.4628 - val_acc: 0.7224\n",
            "Epoch 68/100\n",
            "8000/8000 [==============================] - 6s 742us/step - loss: 0.1260 - acc: 0.9556 - val_loss: 2.4652 - val_acc: 0.7250\n",
            "Epoch 69/100\n",
            "8000/8000 [==============================] - 6s 759us/step - loss: 0.1247 - acc: 0.9558 - val_loss: 2.4784 - val_acc: 0.7234\n",
            "Epoch 70/100\n",
            "8000/8000 [==============================] - 7s 814us/step - loss: 0.1228 - acc: 0.9567 - val_loss: 2.4833 - val_acc: 0.7231\n",
            "Epoch 71/100\n",
            "8000/8000 [==============================] - 6s 797us/step - loss: 0.1222 - acc: 0.9558 - val_loss: 2.4896 - val_acc: 0.7223\n",
            "Epoch 72/100\n",
            "8000/8000 [==============================] - 6s 783us/step - loss: 0.1207 - acc: 0.9556 - val_loss: 2.5083 - val_acc: 0.7227\n",
            "Epoch 73/100\n",
            "8000/8000 [==============================] - 6s 741us/step - loss: 0.1196 - acc: 0.9557 - val_loss: 2.4974 - val_acc: 0.7233\n",
            "Epoch 74/100\n",
            "8000/8000 [==============================] - 6s 744us/step - loss: 0.1181 - acc: 0.9562 - val_loss: 2.5181 - val_acc: 0.7225\n",
            "Epoch 75/100\n",
            "8000/8000 [==============================] - 6s 747us/step - loss: 0.1165 - acc: 0.9558 - val_loss: 2.5029 - val_acc: 0.7228\n",
            "Epoch 76/100\n",
            "8000/8000 [==============================] - 6s 737us/step - loss: 0.1158 - acc: 0.9558 - val_loss: 2.4990 - val_acc: 0.7233\n",
            "Epoch 77/100\n",
            "8000/8000 [==============================] - 6s 749us/step - loss: 0.1148 - acc: 0.9560 - val_loss: 2.5169 - val_acc: 0.7236\n",
            "Epoch 78/100\n",
            "8000/8000 [==============================] - 6s 787us/step - loss: 0.1146 - acc: 0.9557 - val_loss: 2.5514 - val_acc: 0.7216\n",
            "Epoch 79/100\n",
            "8000/8000 [==============================] - 6s 745us/step - loss: 0.1133 - acc: 0.9555 - val_loss: 2.5300 - val_acc: 0.7235\n",
            "Epoch 80/100\n",
            "8000/8000 [==============================] - 6s 742us/step - loss: 0.1121 - acc: 0.9559 - val_loss: 2.5257 - val_acc: 0.7221\n",
            "Epoch 81/100\n",
            "8000/8000 [==============================] - 6s 739us/step - loss: 0.1116 - acc: 0.9557 - val_loss: 2.5402 - val_acc: 0.7223\n",
            "Epoch 82/100\n",
            "8000/8000 [==============================] - 6s 739us/step - loss: 0.1112 - acc: 0.9556 - val_loss: 2.5224 - val_acc: 0.7238\n",
            "Epoch 83/100\n",
            "8000/8000 [==============================] - 6s 736us/step - loss: 0.1105 - acc: 0.9558 - val_loss: 2.5357 - val_acc: 0.7231\n",
            "Epoch 84/100\n",
            "8000/8000 [==============================] - 6s 761us/step - loss: 0.1091 - acc: 0.9555 - val_loss: 2.5663 - val_acc: 0.7228\n",
            "Epoch 85/100\n",
            "8000/8000 [==============================] - 6s 795us/step - loss: 0.1083 - acc: 0.9556 - val_loss: 2.5532 - val_acc: 0.7238\n",
            "Epoch 86/100\n",
            "8000/8000 [==============================] - 6s 755us/step - loss: 0.1080 - acc: 0.9557 - val_loss: 2.5443 - val_acc: 0.7231\n",
            "Epoch 87/100\n",
            "8000/8000 [==============================] - 6s 732us/step - loss: 0.1076 - acc: 0.9556 - val_loss: 2.5557 - val_acc: 0.7241\n",
            "Epoch 88/100\n",
            "8000/8000 [==============================] - 6s 728us/step - loss: 0.1068 - acc: 0.9556 - val_loss: 2.5530 - val_acc: 0.7233\n",
            "Epoch 89/100\n",
            "8000/8000 [==============================] - 6s 741us/step - loss: 0.1067 - acc: 0.9558 - val_loss: 2.5610 - val_acc: 0.7227\n",
            "Epoch 90/100\n",
            "8000/8000 [==============================] - 6s 737us/step - loss: 0.1065 - acc: 0.9555 - val_loss: 2.5675 - val_acc: 0.7226\n",
            "Epoch 91/100\n",
            "8000/8000 [==============================] - 6s 741us/step - loss: 0.1056 - acc: 0.9550 - val_loss: 2.5883 - val_acc: 0.7241\n",
            "Epoch 92/100\n",
            "8000/8000 [==============================] - 6s 736us/step - loss: 0.1046 - acc: 0.9552 - val_loss: 2.5785 - val_acc: 0.7228\n",
            "Epoch 93/100\n",
            "8000/8000 [==============================] - 6s 745us/step - loss: 0.1037 - acc: 0.9554 - val_loss: 2.5765 - val_acc: 0.7229\n",
            "Epoch 94/100\n",
            "8000/8000 [==============================] - 6s 739us/step - loss: 0.1032 - acc: 0.9554 - val_loss: 2.5929 - val_acc: 0.7231\n",
            "Epoch 95/100\n",
            "8000/8000 [==============================] - 6s 739us/step - loss: 0.1031 - acc: 0.9557 - val_loss: 2.5865 - val_acc: 0.7229\n",
            "Epoch 96/100\n",
            "8000/8000 [==============================] - 6s 744us/step - loss: 0.1023 - acc: 0.9552 - val_loss: 2.5842 - val_acc: 0.7245\n",
            "Epoch 97/100\n",
            "8000/8000 [==============================] - 6s 738us/step - loss: 0.1021 - acc: 0.9551 - val_loss: 2.6157 - val_acc: 0.7228\n",
            "Epoch 98/100\n",
            "8000/8000 [==============================] - 6s 795us/step - loss: 0.1017 - acc: 0.9559 - val_loss: 2.5768 - val_acc: 0.7251\n",
            "Epoch 99/100\n",
            "8000/8000 [==============================] - 6s 770us/step - loss: 0.1007 - acc: 0.9557 - val_loss: 2.6000 - val_acc: 0.7232\n",
            "Epoch 100/100\n",
            "8000/8000 [==============================] - 6s 736us/step - loss: 0.1012 - acc: 0.9554 - val_loss: 2.6241 - val_acc: 0.7217\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/network.py:877: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1/while/Exit_3:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_1/while/Exit_4:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
            "  '. They will not be included '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Input: You survived.\n",
            "Translation: ustedes sobrevivieron.\n",
            "Continue? [Y/n]y\n",
            "-\n",
            "Input: Be vigilant.\n",
            "Translation: estate vigilante.\n",
            "Continue? [Y/n]y\n",
            "-\n",
            "Input: You seem busy.\n",
            "Translation: pareces ocupada.\n",
            "Continue? [Y/n]y\n",
            "-\n",
            "Input: Meet me at 2:30.\n",
            "Translation: las hgalo y y en l no es?\n",
            "Continue? [Y/n]y\n",
            "-\n",
            "Input: Give me a day.\n",
            "Translation: dame un da.\n",
            "Continue? [Y/n]n\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}